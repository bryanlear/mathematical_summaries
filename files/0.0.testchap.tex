\documentclass[../Main.tex]{subfiles}

\begin{document}
\chapter{Game Theory}
\textbf{Strategic form/normal form/matrix games:} Games in which all participants act simultaneously and without knowledge of other players' actions.
\begin{itemize}
    \item Set of players (agents)
    \item Set of actions 
    \item Set of payoff/utility functions
    \item Information structure players can access
\end{itemize}

\section{Finite Games/Nash Equilibria}
\subsection{Finite Games}
\defn{Strategic form of game/Finite game}{A strategic forms game is a triplet $\langle \mathcal{I}, (S_i)_{i \in \mathcal{I}}, (u_i)_{i \in \mathcal{I}} \rangle$ such that
    \begin{itemize}
        \item[$\blacktriangleright$] $\mathcal{I}$: finite number of players, where $N = \mathcal{I} = \{1, 2, \ldots, n\}$
        \item[$\blacktriangleright$] $S_i$: set of actions (decisions, strategies) for player $i$
        \item[$\blacktriangleright$] $s_i \in S_i$: actions (decisions, strategies) for player $i$
        \item[$\blacktriangleright$] $u_i : S \longrightarrow \mathbb{R}$: the payoff (utility) function of player $i$, where $S = \prod_{i=1}^n S_i$ is the set of actions of all players
    \end{itemize}
}

\subsection*{Notation}
\begin{itemize}
    \item[$\blacktriangleright$] $s = (s_1, \ldots, s_n) \in S = \prod_{i=1}^n S_i = S_1 \times S_2 \times \cdots \times S_n$
    \item[$\blacktriangleright$] $s$: decision/action/strategy profile
    \item[$\blacktriangleright$] $s_{-i} = (s_1, s_2, \ldots, s_{i-1}, s_{i+1}, s_{i+2}, \ldots, s_n)$
\end{itemize}

\textbf{Strategy:} Complete description of how to play the game. Requires full contingent planning (full description how to play in every contingency).

\subsection*{General Setup of $n$-Player Finite Game}

\begin{itemize}
    \item[$\blacktriangleright$] Players: $n$-players with $i \in N = \{1, 2, \ldots, n\}$
    \item[$\blacktriangleright$] decision/action/strategy for Player $i$: $s_i \in S_i$
    \begin{itemize}
        \item[$\blacktriangleright$] $S_i$ is a finite set
    \end{itemize}
    \item[$\blacktriangleright$] $s = (s_1, \ldots, s_n) \in S = S_1 \times S_2 \times \cdots \times S_n$
    \begin{itemize}
        \item[$\blacktriangleright$] $s$: decision/action/strategy profile
    \end{itemize}
    \item[$\blacktriangleright$] $s_{-i} = (s_1, s_2, \ldots, s_{i-1}, s_{i+1}, s_{i+2}, \ldots, s_n)$
    \item[$\blacktriangleright$] Payoff function: $u_i(s_i, s_{-i})$ with $u_i : S \to \mathbb{R}$
    \begin{itemize}
        \item[$\blacktriangleright$] Each player has to maximize $u_i$ over $s_i \in S_i$
    \end{itemize}
\end{itemize}

\begin{itemize}
    \item[$\blacktriangleright$] Player 1 and Player 2
    \item[$\blacktriangleright$] $S_1 = \{1, \ldots, p\}$ finite set
    \item[$\blacktriangleright$] $S_2 = \{1, \ldots, m\}$ finite set
    \item[$\blacktriangleright$] $u_1: p \times m$ matrix
    \item[$\blacktriangleright$] $u_2: m \times p$ matrix
    \item[$\blacktriangleright$] Zero-sums game
    \begin{itemize}
        \item[$\blacktriangleright$] When $u := u_1 = -u_2$
        \item[$\blacktriangleright$] Player 2 plays minimizing $u$
    \end{itemize}
\end{itemize}

\begin{center}
    Player 2 \\
    \begin{tabular}{|c|c|c|c|}
        \cline{2-4}
        \multicolumn{1}{c|}{} & D & E & F \\
        \hline
        A & $(a, b)$ & $(c, d)$ & $(e, f)$ \\
        \cline{2-4}
        Player 1 \quad B & $(g, h)$ & $(i, j)$ & $(k, l)$ \\
        \cline{2-4}
        C & $(m, n)$ & $(o, p)$ & $(q, r)$ \\
        \hline
    \end{tabular}
\end{center}

\begin{itemize}
    \item[$\blacktriangleright$] Player 1 chooses row with respect to the first component
    $X_1 = \{A, B, C\}$
    \item[$\blacktriangleright$] Player 2 chooses column with respect to the second
    component $X_2 = \{D, E, F\}$
\end{itemize}

\subsection{Dominant Equilibrium: Optimality of Game}
For i player, a dominant strategy is one that yields the highest payoff, \textit{regardless of other players' actions}. A \textbf{Dominant Strategy Equilibrium} occurs when \textit{every} player has a clear best choice irrespective of others' and there is this no incentive for any player to deviate. (e.g., Prisoner's Dilemma). 

\textbf{Nash Equilibrium:} Set of strategies, for each player, such that \textit{no player can improve payoff by unilaterally changing only their own strategy} (assuming all players stick to chosen strategies). Note: a game can have multiple Nash equilibria and they don't always mean the best possible collective outcome for all players.

Every dominant strategy equilibrium is also Nash equilibrium. NOT the other way around though. 

\defn{Dominant strategy}{
A strategy $s_i \in S_i$ is dominant for Player $i \in N$ if
$$u_i(s_i, s_{-i}) \geq u_i(s_i', s_{-i}), \quad \forall (s_i', s_{-i}) \in S_i \times S_{-i}$$
where, $s_{-i}$ is collection of strategies chosen by all players except player i.
}

\defn{Dominant equilibrium}{
A strategy profile $s^* \in S$ is the dominant strategy equilibrium if for each Player $i \in N$, $s_i^* \in S_i$ is the dominant strategy.
\begin{itemize}
    \item[$\blacktriangleright$] We observe that "Confess" is the dominant equilibrium in Prisoner's dilemma game
    \item[$\blacktriangleright$] Rational players will choose the dominant strategy
\end{itemize}
}

\defn{Strictly dominated strategy}{
A strategy $s_i \in S_i$ is strictly dominated for player $i \in N$ if there exists some $s_i' \in S_i$ such that
$$u(s_i', s_{-i}) > u(s_i, s_{-i}), \quad \forall s_{-i} \in S_{-i}$$
\begin{itemize}
    \item[$\blacktriangleright$] Can obtain the dominant equilibrium by eliminating strictly dominated strategies (\textbf{iterated elimination of strictly dominated strategies (IESDS))}.
    \item[$\blacktriangleright$] Rational players do not choose the strictly dominated strategy
\end{itemize}
Therefore, if there exists another strategy $s_i'$ such that choosing $s_i'$  \textit{always} yields a strictly higher payoff for player $i$. regardless of what strategies other players $s_{-i}$ choose.}

\subsection*{IESDS} 

Method to simplify a game and find a solution/equilibrium. \\

Let $S_j^k$ be set of strategies for player j that have survived elimination up to iteration $k$. \\

Let $S_{-i}^k = X_{j \neq i}S_j^k$ be set of strategy profiles for players other than $i$ using strategies available at iteration $k$.\\

\textbf{Pseudocode:}
\begin{verbatim}
    Initialize S_i_current = S_i for all players i in N
Set strategies_eliminated_this_round = true

WHILE strategies_eliminated_this_round == true:
    Set strategies_eliminated_this_round = false
    FOR EACH player i in N:
        Let S_i_next_round = S_i_current
        FOR EACH strategy s_prime_i in S_i_current:
            Set is_dominated = false
            FOR EACH strategy s_double_prime_i in S_i_current (where s_double_prime_i != s_prime_i):
                Set s_double_prime_dominates_s_prime = true
                // Check if s_double_prime_i strictly dominates s_prime_i
                // against all combinations of opponents' current strategies S_minus_i_current
                FOR EACH strategy_profile_s_minus_i in S_minus_i_current: 
                    IF u_i(s_double_prime_i, s_minus_i) <= u_i(s_prime_i, s_minus_i):
                        s_double_prime_dominates_s_prime = false
                        BREAK // s_double_prime_i does not dominate s_prime_i w.r.t. this s_minus_i
                IF s_double_prime_dominates_s_prime == true:
                    is_dominated = true
                    BREAK // s_prime_i is dominated by s_double_prime_i
            IF is_dominated == true:
                Remove s_prime_i from S_i_next_round
                strategies_eliminated_this_round = true
        Set S_i_current = S_i_next_round // Update player i's strategy set for this iteration

Output: The final sets S_i_current for all players.
\end{verbatim}

\subsection{Nash Equilibrium: Optimality of Game}
\begin{itemize}
    \item[$\blacktriangleright$] N-player noncooperative game
    \item[$\blacktriangleright$] Rationality and optimality are key underlying assumptions
    \item[$\blacktriangleright$] No incentive to deviate once every player is in Nash
\end{itemize}
\defn{Nash Equilibrium (state)}{
The strategy profile $s^* = (s_1^*, \dots, s_n^*) \in S$ is called a Nash
equilibrium of the game if for all $i$, $i=1,2,\dots,n$,\[
u_i(s_i^*, s_{-i}^*) \ge u_i(s_i, s_{-i}^*), \quad \forall s_i \in S_i\]
Thus, no single player has an incentive to change only their own strategy. If player $i$ unilaterally deviates from $s^*$ to $s_i$, while $-i$ stick to $s^*$, player $i$ \textit{will NOT} achieve a strictly better payoff (either same or worse).
}
\defn{Best response function (tool)}{
The best response function \textbf{(correspondence)} $B_i(s_{-i})$ is defined by
$B_i: S_{-i} \to S_i$
$$B_i(s_{-i}) = \arg \max_{s_i \in S_i} u_i(s_i, s_{-i})$$
$$= \{s_i \in S_i \mid u_i(s_i, s_{-i}) \geq u_i(s_i', s_{-i}), \forall s_i' \in S_i\}$$
\begin{itemize}
    \item[$\blacktriangleright$]{It is sometimes correspondence, since given $s_{-i} \in S_{-i}$, there can be multiple $s_i \in S_i$}
    \item[$\blacktriangleright$] It is a multi-valued (set-valued) function
\end{itemize}
}

$B_i$ defines (set) strategy(s) such that player $i$'s payoff is maximized, \textit{given} $-i$ are playing $s_{-1}$.

Output of $B_i$ can be a set of strategies too if multiple yield same maximum payoff.\\

A strategy $s^* = (s^*_1,s^*_2,...,s^*_n)$ is \textbf{Nash Equilibrium} if every player's strategy in that profile is a best response to the strategies of all other players in that profile. Thus, $\forall i \in N$: $s^*_i \in B_i(s^*_{-1})$:

\propp{The strategy profile $s^* = (s_1^*, \ldots, s_n^*) \in S$ is a Nash equilibrium of the game if and only if $$s_i^* \in B_i(s_{-i}^*), \quad \forall i \in N = \{1, 2, \ldots, n\}$$}{
\begin{itemize}
    \item[$\blacktriangleright$] If part: since $s_i^* \in B_i(s_{-i}^*)$ for all $i \in N$, the result is true by definition
    \item[$\blacktriangleright$] Only if part: since $s^* \in S$ is a NE, the result follows from definition of the best response function
\end{itemize}
}

Current strategy maxed out payoff $=$ \textit{No} incentive to unilaterally change strategy.
\begin{center}
    \includegraphics[width = 7cm, height = 7cm]{files/nash.png}
\end{center}

\defn{Nash equilibrium for two player game}{Simplified to two player game ($n=2$)

The strategy profile $s^* = (s_1^*, s_2^*) \in S_1 \times S_2$ is called a Nash equilibrium of the game if
\begin{align*}
    u_1(s_1^*, s_2^*) &\geq u_1(s_1, s_2^*), \quad \forall s_1 \in S_1 \\
    u_2(s_1^*, s_2^*) &\geq u_2(s_1^*, s_2), \quad \forall s_2 \in S_2
\end{align*}
}

Each player wants to choose their strategy to maximize their own payoff, keeping in mind that the other player is also trying to do the same.\\

\textbf{Core Idea: No Unilateral Incentive to Deviate (No Regrets)}\\

\textbf{e.g.,} Prisoner's Dilemma (PAyoff does not lead to best result at NE):\\

\textit{'The dilemma is that individual rationality (each prisoner choosing their dominant strategy to minimize their own sentence) leads to a collectively suboptimal outcome where both are worse off than if they had managed to cooperate. Even if they had agreed beforehand to Stay Silent, the incentive to betray the other for a chance at freedom (or a reduced sentence if the other also betrays) is very strong. This highlights the conflict between individual incentives and mutual benefit, and the difficulty of achieving cooperation in the absence of trust and binding agreements.'}

\subsection{Saddle-Point Equilibrium}

\defn{Saddle-Point Equilibrium}{NE for a \textbf{2-player zero-sum} game ($u = u_1 = -u_2$)

Strategy profile $s^* = (s^*_1, s^*_2) \in S_1 * S_2$ is a saddle-point equilibrium of 2-player game if
\begin{align*}
     u(s_1, s^*_2) \leq u(s^*_1, s^*_2) \leq u(s^*_1, s_2), \forall(u(s_1, s_2) \in S_1 * S_2
\end{align*}
\begin{itemize}
    \item[$\blacktriangleright$]{$u(s^*_1, s^*_2):$ \textbf{value of the game}}
\end{itemize}
}

\textbf{Minimax strategy (player 2 - minimizer of player's 1 payoff)}: For each column, player 2 identifies max. possible payoff Player 1 could achieve if player 2 chooses that column (assuming player 1 will try to maximize their payoff for that column). \textbf{Column Maximum***}

Player 2 then chooses strategy (column) that corresponds to the \textbf{minimum of these column maximums} = \textbf{Minimax value} of the game (From player 1's perspective, representing the maximum payoff player 2 is willing to concede. 
\begin{center}
    \textit{Maximin value (Player 1) = Minimax value (Player 2)}

    =

    \textit{\textbf{Value of the Game $(\mathbf{V})$}}
\end{center}

%%%%%%%%%%%%%%#############################################
%%%%%%%%%%%%%%#############################################
%%%%%%%%%%%%%%#############################################



\exm{Saddle Point in Pure Strategies}{

Consider the following \textit{PAYOFF MATRIX} for Player 1 in a 2-player 0-sum game.
Entries in matrix $=$ Payoff to Player 1. $(u= u1 =−u2)$

\vspace{1em} % Adds a small vertical space

% Payoff Matrix
\begin{center} % Center the table
\begin{tabular}{l | c c | c}
\toprule
                      & \textbf{Player 2:} & \textbf{Player 2:} & \\
                      & \textbf{Strategy Y1} & \textbf{Strategy Y2} & \textbf{Row Minimums} \\
\midrule
\textbf{Player 1: Strategy X1} & 4                     & \textbf{2}            & 2                \\
\textbf{Player 1: Strategy X2} & 3                     & 1                     & 1                \\
\midrule
\textbf{Column Maximums}      & 4                     & \textbf{2}            &                  \\
\bottomrule
\end{tabular}
\end{center}

\vspace{1em}

\textbf{Goal:} To find maximin and minimax values to identify saddle point:

\subsection*{1. Player 1's Maximin Strategy (Maximizing minimum guaranteed payoff)}
Player 1 looks at minimum payoff they could receive for each of their strategies:
\begin{itemize}
    \item If Player 1 plays Strategy X1, the minimum payoff is $\min(4, 2) = 2$.
    \item If Player 1 plays Strategy X2, the minimum payoff is $\min(3, 1) = 1$.
\end{itemize}
Player 1 wants to choose the strategy that maximizes this minimum payoff. The maximum of $\{2, 1\}$ is 2.
Thus, Player 1's maximin strategy is X1, and the \textbf{Maximin value = 2}.

\subsection*{2. Player 2's Minimax Strategy (Minimizing Player 1's maximum possible gain)}
Player 2 looks at the maximum payoff Player 1 could achieve for each of Player 2's strategies:
\begin{itemize}
    \item If Player 2 plays Strategy Y1, the maximum payoff Player 1 can get is $\max(4, 3) = 4$.
    \item If Player 2 plays Strategy Y2, the maximum payoff Player 1 can get is $\max(2, 1) = 2$.
\end{itemize}
Player 2 wants to choose the strategy that minimizes maximum payoff for Player 1. The minimum of $\{4, 2\}$ is 2.
Thus, Player 2's minimax strategy is Y2, and the \textbf{Minimax value = 2} (from Player 1's perspective).
}

\subsection*{Saddle Point and Value of the Game}
Since Maximin value (2) $=$ Minimax value (2) $\rightarrow$ Saddle point exists.\\

\textbf{$V$} $= 2$\\

Saddle point occurs at strategy profile where Player 1 plays \textbf{Strategy X1} and Player 2 plays \textbf{Strategy Y2}. The payoff at this point is \textbf{2} (to Player 1).\\

Looking at the entry `2` in the matrix (at the intersection of X1 and Y2):
\begin{itemize}
    \item It is the minimum value in its row (Row X1: values are $\{4, \mathbf{2}\}$).
    \item It is the maximum value in its column (Column Y2: values are $\{\mathbf{2}, 1\}$).
\end{itemize}
Dual property (minimum of its row and maximum of its column) is characteristic of a saddle point in a payoff matrix.

\subsection*{Stability of the Saddle Point (Connection to Nash Equilibrium)}{
At saddle point (X1, Y2):
\begin{itemize}
    \item If Player 1 (currently playing X1) unilaterally considers switching to Strategy X2 (while Player 2 continues to play Y2), Player 1's payoff would decrease from 2 to 1. Therefore, Player 1 has no incentive to switch.
    \item If Player 2 (currently playing Y2) unilaterally considers switching to Strategy Y1 (while Player 1 continues to play X1), Player 1's payoff would increase from 2 to 4 $=$ Player 2's payoff would change from -2 to -4 (zero-sum game), which is worse for Player 2. Therefore, Player 2 has no incentive to switch.
\end{itemize}
Since neither player has an incentive to unilaterally deviate from strategy profile (X1, Y2), saddle point is also a NE for the above 0-sum game.}\\

\textbf{Properties of Zero-Game:}
\begin{itemize}
    \item[$\blacktriangleright$] \textbf{Value is unique:}
    \begin{itemize}
        \item[$\blacktriangleright$] There is 1 value which is $=$ upper and lower values of the game.
    \end{itemize}
    \item[$\blacktriangleright$] \textbf{Order Interchangeability:}
    \begin{itemize}
        \item[$\blacktriangleright$] if $(x_1, x_2)$ and $(y_1, y_2)$ are saddle-point solutions, then $(x_1, y_2)$ and $(y_1, x_2)$ are also saddle-point solution
        \item[$\blacktriangleright$] $(x_1, x_2)$ and $(y_1, y_2)$ lead to \textit{same value} of the 0-sum game
    \end{itemize}
\end{itemize}

\subsection{Mixed Strategies and Mixed Nash Equilibrium}
\begin{itemize}
    \item[$\blacktriangleright$] Probability vector in strategy space
    \item[$\blacktriangleright$] Randomization of the strategy (action) space
    \item[$\blacktriangleright$] Payoff becomes expected value
\end{itemize}


\section*{Mixed Strategies and Expected Payoff}

\begin{itemize}
    \item Let $\Sigma_i$ be set of probabilities on $S_i$.
    \item Let $\sigma_i \in \Sigma_i$ is probability on $S_i$. $\sigma_i$ (also called the simplex on $\Sigma_i$)
    \item Note $\sigma = (\sigma_1, \sigma_2, \dots, \sigma_n)$, $\Sigma = \Sigma_1 \times \dots \times \Sigma_n$
    \item Similarly $\sigma_{-i}$ and $\Sigma_{-i}$
    \item With $\sigma_i \in \Sigma_i$, strategy set $S_i$ can be randomized. \textbf{Randomization is independent}.
    \item Expected payoff is given by $u_i : \Sigma \rightarrow \mathbb{R}$ with
    \[
        u_i(\sigma) = u_i(\sigma_i, \sigma_{-i}) = E[u_i(s_i, s_{-i})] = \sum_{s \in S} \left( \prod_{j=1}^{n} \sigma_j(s_j) \right) u_i(s)
    \]
    (Note: $s=(s_1, \dots, s_n)$ is a pure strategy profile and $\sigma_j(s_j)$ is probability player $j$ plays pure strategy $s_j$.)
\end{itemize}

Let $|S_1| = p$ and $|S_2|=q$\\

$\sigma_1 = (\sigma^{(1)}_1,...,\sigma^{(p)}_1$) with $\sum^p_{i=1} \sigma^{i}_1 = 1$ and $ \sigma^{i}_1 \in [0,1]$\\

$\sigma_2 = (\sigma^{(1)}_2,...,\sigma^{(p)}_2$) with $\sum^p_{i=1} \sigma^{i}_2 = 1$ and $ \sigma^{i}_2 \in [0,1]$\\

$\sigma_1$ and $\sigma_2$ are probability measures on $S_1$ and $S_2$. They are probability mass functions\\

Always choosing pure strategy (same option) is predictable and can be \textit{exploited}. A \textbf{mixed strategy} is a way to be unpredictable. Player chooses a \textit{probability distribution} over their available actions.\\

\exm{Mixed}{
\begin{itemize}
    \item[$\blacktriangleright$] If $S_1 = \{A,B\}$, then player $1$ selects $A$ with probability $\sigma^{(1)}_1$ and $B$ with probability $1-\sigma^{(1)}_1$
    \item [$\blacktriangleright$] $\sigma_1 = (\sigma^{(1)}_1, 1-\sigma^{(1)}_1)$
    \item [$\blacktriangleright$] If $S_2 = \{C,D\}$ then $\sigma_2 = (\sigma^{(1)}_2, 1-\sigma^{(1)}_2)$
    \item [$\blacktriangleright$] \textbf{Expected/probabilistic payoff} for Player $1$ is:
    \begin{align*}
u_1(\sigma_1, \sigma_2) &= \sigma_1^{(1)}\sigma_2^{(1)}u_1(A, C) \\
& \quad + (1-\sigma_1^{(1)})\sigma_2^{(1)}u_1(B, C) \\
& \quad + \sigma_1^{(1)}(1-\sigma_2^{(1)})u_1(A, D) \\
& \quad + (1-\sigma_1)(1-\sigma_2^{(1)})u_1(B, D)
\end{align*}
\end{itemize}

$\sigma^{1}_1 \sigma^{2}_1u_1(A, C)$: Chance Player $1$ plays $A$ and Player $2$ plays $C$ times Player $1$'s payoff $u₁(A, C)$ if that happens and so on x$4$ for all the possible combinations

}

\defn{Mixed Nash equilibrium}{
A mixed strategy profile $\sigma^* \in \Sigma$ is a mixed (strategy) Nash equilibrium if for any player $i \in N$,
$$u_i(\sigma_i^*, \sigma_{-i}^*) \geq u_i(\sigma_i, \sigma_{-i}^*), \quad \forall \sigma_i \in \Sigma_i$$
}
\rmkb{
\begin{itemize}
    \item[$\blacktriangleright$] Previous definition NE is deterministic, \textbf{pure NE}.
    \item[$\blacktriangleright$] Mixed NE $=$ Randomization
    \item[$\blacktriangleright$] Every finite (matrix) game admits mixed strategy NE
\end{itemize}
}
%%%%%%%%%%%%%%#############################################
\thm{Mixed NE with best response}{
A mixed strategy profile $\sigma^* \in \Sigma$ is a mixed NE \textit{if and only if} for any player $i \in N$,

\begin{center}
    $\sigma_i^* \in B_i(\sigma_{-i}^*) = \arg\max_{\sigma_i \in \Sigma_i} u_i(\sigma_i, \sigma_{-i}^*)
= \{\sigma_i \in \Sigma_i \mid u_i(\sigma_i, \sigma_{-i}^*) \ge u_i(\sigma_i', \sigma_{-i}^*), \forall \sigma_i' \in \Sigma_i\}$
\end{center}
}
\rmkb{
\begin{itemize}
    \item \textbf{$B_i$}: Best response correspondence of Player $i$
    \item Proof is analogous to that of pure NE case 
\end{itemize}
Check player $i$'s strategy $\sigma^*_i$ against \textit{every other possible mixed strategy $\sigma'_i$ but there are infinitely ways to mix probabilities therefore not feasible}. The solution is to check that player $i$'s mixed strategy $\sigma^*_i$ gives a payoff that is \textbf{at least as good as any of the player's individual pure strategies $(s'_i)$}.
Thus, a situation is NE when every player's chosen $s_i$ is a $B_i$ to $S_{-i}$ $= equilibrium =$ No reason to change strategy:
}
\propp{
A mixed strategy profile $\sigma^* \in \Sigma$ is a mixed NE \textit{if and only if} for any player $i \in N$,
\begin{center}
    $
    u_i(\sigma_i^*, \sigma_{-i}^*) \ge u_i(s_i', \sigma_{-i}^*), \quad \forall s_i' \in S_i
    $
\end{center}
}{
$u_i(\sigma_i', \sigma_{-i}^*) = \sum_{j=1}^{|S_i|} \sigma_i'^{(j)} u_i(s_j, \sigma_{-i}^*)$\\

$\sum_{j=1}^{|S_i|} \sigma_i'^{(j)} u_i(s_j, \sigma_{-i}^*) \le \sum_{j=1}^{|S_i|} \sigma_i'^{(j)} u_i(\sigma_i^*, \sigma_{-i}^*)$\\

$= u_i(\sigma_i^*, \sigma_{-i}^*) \sum_{j=1}^{|S_i|} \sigma_i'^{(j)} = u_i(\sigma_i^*, \sigma_{-i}^*)$
}

\textbf{Support of a mixed strategy}: Any pure strategy $s_i$ that is played with a probability $> 0$.
\prop{
A mixed strategy profile $\sigma^* \in \Sigma$ is a mixed strategy NE if and only if for any $i \in N$, every pure strategy in the support $\sigma^* \in \Sigma_i$ is the best response to $\sigma^*_{-i} \in \Sigma^*_{-i}$.\\

For any $s_i \in \Sigma_i$ with:
\begin{center}
    $\mathbb{P}(s_i) = \sigma_i^*(s_i) > 0$\\

    $s_i \in \arg\max_{s_j \in S_i} u_i(s_j, \sigma_{-i}^*) \iff s_i \in B_i(\sigma_{-i}^*)$
\end{center}

}
\rmkb{
\begin{itemize}
    \item[$\blacktriangleright$]Each pure strategy $s_i$ is the best response to the mixed strategies of other players $\sigma^*_-i$
    \item[$\blacktriangleright$] Important for characterization of mixed NE
\end{itemize}

The support is the set of all pure strategies that are actually played with a \textbf{non-zero probability} while the the proposition says that a mixed strategy is a NE if and only if \textbf{every pure strategy the player is actively using (i.e., in the support) is itself a best response.}
}

For every \textbf{pure} strategy in the support to be a best response, they must all yield the exact \textbf{same expected payoff}. If $1 / pure_strategies$ in mix gave a higher expected payoff than another, player would have incentive to shift all probability to that better strategy.

\subsection*{Indifference Principle}
The equation says that in a mixed NE, the expected payoff for playing \textbf{any pure strategy in the support} is the same.

\propp{
Under strategy of $(\sigma^*_i, \sigma^*_{-i}) \in \Sigma_i*\Sigma_{-i}$, if $s_i, s'_i \in S_i$ are supports of $\sigma^*_i \in \Sigma_i$, then:
\begin{center}
    $u_i(s_i, \sigma_{-i}^*) = u_i(s_i', \sigma_{-i}^*) = u_i(\sigma_i^*, \sigma_{-i}^*), \quad \forall i=1, \dots, n$
    (since mixed's payoff is weighted average of identical payoffs)
\end{center}
}{
if $u_i(s_i, \sigma_{-i}^*) > u_i(s_i', \sigma_{-i}^*)$ then reducing probability of playing $s'_i$ leads to increasing probability of playing $s_i$ which implies that $\sigma^*_i$ is not the best response to $\sigma^*_{-1}$.}

\textit{Thus, in a Mixed NE player must be indifferent to all the pure strategies player is actively mixing between}.\\

Let $A$ be a payoff matrix for Player $1$ and $B$ for Player $2$, where Player $1$ chooses row and Player $2$ chooses column for optimal decisions:

\defn{Matrix representation of NE (2 players)}{
A pair $(\sigma^*_1, \sigma^*_2) \in \Sigma_1$ x $\Sigma_2$ is said to constitute a NE in mixed strategies if:
\begin{center}
    \begin{itemize}
        \item[$\blacktriangleright$]Player $1$ $\sigma_1^{*\top} A \sigma_2^* \ge \sigma_1^\top A \sigma_2^*, \quad \forall \sigma_1 \in \Sigma_1$
        \item[$\blacktriangleright$]Player $2$ $\sigma_1^{*\top} B \sigma_2^* \ge \sigma_1^\top B \sigma_2, \quad \forall \sigma_2 \in \Sigma_2$
    \end{itemize}
\end{center}
}

Let $A = -B$. Then the definition of mixed NE is equivalent to the mixed saddle-point equilibrium:

\defn{Mixed saddle-point equilibrium}{
A pair $(\sigma_1^*, \sigma_2^*) \in \Sigma_1 \times \Sigma_2$ is said to constitute a saddle-point solution in mixed strategies if
$$ \sigma_1^\top A \sigma_2^* \le (\sigma_1^*)^\top A \sigma_2^* \le (\sigma_1^*)^\top A \sigma_2, \quad \forall (\sigma_1, \sigma_2) \in \Sigma_1 \times \Sigma_2 $$

\begin{itemize}
    \item[$\blacktriangleright$] Note
    $$ (\sigma_1^*)^\top A \sigma_2^* = \max_{\sigma_1 \in \Sigma_1} \min_{\sigma_2 \in \Sigma_2} \sigma_1^\top A \sigma_2 = \min_{\sigma_2 \in \Sigma_2} \max_{\sigma_1 \in \Sigma_1} \sigma_1^\top A \sigma_2 $$
    \item[$\blacktriangleright$] This is the value of the zero-sum game
    \item[$\blacktriangleright$] For zero-sum games, a NE $=$ Saddle-Point
\end{itemize}
}

\exm{Matching Penny Game}{
\begin{center}
\begin{tabular}{cc|c|c|}
  & \multicolumn{1}{c}{} & \multicolumn{2}{c}{Player 2} \\
  & \multicolumn{1}{c}{} & \multicolumn{1}{c}{Head}  & \multicolumn{1}{c}{Tail} \\\cline{3-4}
  Player 1 & Head & $(1, -1)$ & $(-1, 1)$ \\\cline{3-4}
  & Tail & $(-1, 1)$ & $(1, -1)$ \\\cline{3-4}
\end{tabular}
\end{center}

\begin{itemize}
    \item[$\blacktriangleright$] There does not exist pure NE (or saddle-point equilibrium). 
    \begin{itemize}
        \item[$\blacktriangleright$] If they play (Head, Head), Player $2$ gets $-1$ and would prefer to switch to Tail to get $+1$
        \item[$\blacktriangleright$] If they play (Head, Tail), Player $1$ gets $-1$ and would prefer to switch to Tail to get $+1$
        \item[$\blacktriangleright$] so on...
    \end{itemize}
    In each case player has incentive to switch $=$ no NE, thus a mixed strategy must be found:
    \item[$\blacktriangleright$] Compute mixed NE (or saddle-point equilibrium)
    \item[$\blacktriangleright$] Apply previous proposition $1.14$
\end{itemize}

}
\textbf{Recall} Proposition $1.14$
\thm{ Mixed Nash equilibrium with best response | Practical Application}{
\textit{When a player is indifferent, they are willing to mix their strategies.}
A mixed strategy profile $\sigma^* \in \Sigma$ is a mixed (strategy) NE if and only if for any player $i \in N$,
$$ \sigma_i^* \in B_i(\sigma_{-i}^*) = \arg\max_{\sigma_i \in \Sigma_i} u_i(\sigma_i, \sigma_{-i}^*) $$
$$ = \{\sigma_i \in \Sigma_i \mid u_i(\sigma_i, \sigma_{-i}^*) \ge u_i(\sigma_i', \sigma_{-i}^*), \forall \sigma_i' \in \Sigma_i\} $$
}

\subsection*{Mixed Strategies and Expected Payoffs}

Let Player 1's mixed strategy be $\sigma_1 = (p, 1-p)$ and Player 2's be $\sigma_2 = (q, 1-q)$, with $p, q \in [0,1]$.

For a given $\sigma_2$, the expected payoff of Player 1 can be written as:
\begin{align*}
    \text{(1) Player 1 playing Head: } E_1(\text{Head}) &= q \cdot (1) + (1-q) \cdot (-1) = 2q - 1 \\
    \text{(2) Player 1 playing Tail: }  E_1(\text{Tail})  &= q \cdot (-1) + (1-q) \cdot (1) = 1 - 2q
\end{align*}

\textbf{Principle of indifference}: a player will only be willing to play a mixed strategy i.e., choose probability, if they are perfectly indifferent between their pure strategies. 

Player 1 is indifferent when $2q - 1 = 1 - 2q \implies q = \frac{1}{2}$.
\begin{itemize}
    \item When $q < \frac{1}{2} \implies E_1(\text{Head}) < E_1(\text{Tail})$
    \item When $q = \frac{1}{2} \implies E_1(\text{Head}) = E_1(\text{Tail})$
    \item When $q > \frac{1}{2} \implies E_1(\text{Head}) > E_1(\text{Tail})$
\end{itemize}

For a given $\sigma_1$, the expected payoff of Player 2 is:
\begin{align*}
    \text{(3) Player 2 playing Head: } E_2(\text{Head}) &= p \cdot (-1) + (1-p) \cdot (1) = 1 - 2p \\
    \text{(4) Player 2 playing Tail: }  E_2(\text{Tail})  &= p \cdot (1) + (1-p) \cdot (-1) = 2p - 1
\end{align*}

Player 2 is indifferent when $1 - 2p = 2p - 1 \implies p = \frac{1}{2}$.
\begin{itemize}
    \item When $p < \frac{1}{2} \implies E_2(\text{Head}) > E_2(\text{Tail})$
    \item When $p = \frac{1}{2} \implies E_2(\text{Head}) = E_2(\text{Tail})$
    \item When $p > \frac{1}{2} \implies E_2(\text{Head}) < E_2(\text{Tail})$
\end{itemize}

Thus, zero-sum game with no \textit{Pure Strategy NE} since there is no stable outcome if $P_1$ knows $P_2$ and $P_2$ knows $P_1$ leading to cycle of responses. Players must therefore be \textbf{unpredictable} by adopting a \textit{mixed strategy} choosing action based on \textbf{probability distribution}.

\textbf{Player i's strategy $\sigma_i$}: Plays head with probability \textit{$p$} and tail with \textit{$1-p$} $\sigma_i = (p, 1-p)$.

\subsection*{Best $B_i$ and NE}
Player's' optimal strategy for every possible strategy of the opponent.
\[
\begin{cases} 
    p = 0 \text{ (playing Tail)} & \text{if } q < \frac{1}{2} \\
    p \in [0, 1] & \text{if } q = \frac{1}{2} \\
    p = 1 \text{ (playing Head)} & \text{if } q > \frac{1}{2}
\end{cases}
\]
The best response of Player 2 for $\sigma_1$ is:
\[
B_2(\sigma_1) = 
\begin{cases} 
    q = 1 \text{ (playing Head)} & \text{if } p < \frac{1}{2} \\
    q \in [0, 1] & \text{if } p = \frac{1}{2} \\
    q = 0 \text{ (playing Tail)} & \text{if } p > \frac{1}{2}
\end{cases}
\]

Best response functions leads to Mixed Strategy NE $(\sigma_1^*, \sigma_2^*) = ((\frac{1}{2}, \frac{1}{2}), (\frac{1}{2}, \frac{1}{2}))$. (Neither player has an incentive to deviate)

\begin{figure}[htbp] % Use [htbp] for better float placement
    \centering

    % --- Top Row of Graphs ---
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                % Size is controlled here, not with \scale
                width=\linewidth, 
                height=5cm,
                title={Best Response of P1: $p = B_1(q)$},
                xlabel={$q$ (P2's prob of Head)},
                ylabel={$p$ (P1's prob of Head)},
                xmin=0, xmax=1,
                ymin=0, ymax=1,
                xtick={0, 0.5, 1},
                ytick={0, 0.5, 1},
                xticklabels={$0$, $\frac{1}{2}$, $1$},
                yticklabels={$0$, $\frac{1}{2}$, $1$},
                grid=major,
            ]
            \addplot[blue, very thick] coordinates {(0,0) (0.5,0)};
            \addplot[blue, very thick] coordinates {(0.5,1) (1,1)};
            \addplot[blue, very thick] coordinates {(0.5,0) (0.5,1)};
            \end{axis}
        \end{tikzpicture}
        \caption{Best response of Player 1.}
        \label{fig:p1_br_final}
    \end{subfigure}
    \hfill % Automatically creates horizontal space
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                width=\linewidth,
                height=5cm,
                title={Best Response of P2: $q = B_2(p)$},
                xlabel={$q$ (P2's prob of Head)},
                ylabel={$p$ (P1's prob of Head)},
                xmin=0, xmax=1,
                ymin=0, ymax=1,
                xtick={0, 0.5, 1},
                ytick={0, 0.5, 1},
                xticklabels={$0$, $\frac{1}{2}$, $1$},
                yticklabels={$0$, $\frac{1}{2}$, $1$},
                grid=major,
            ]
            \addplot[red, very thick] coordinates {(1,0) (1,0.5)};
            \addplot[red, very thick] coordinates {(0,0.5) (0,1)};
            \addplot[red, very thick] coordinates {(0,0.5) (1,0.5)};
            \end{axis}
        \end{tikzpicture}
        \caption{Best response of Player 2.}
        \label{fig:p2_br_final}
    \end{subfigure}

    \vspace{0.5cm} % A smaller, fixed space between rows

    % --- Bottom (Intersection) Graph ---
    \begin{subfigure}[b]{0.6\textwidth} % This graph can be a bit larger
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                width=\linewidth,
                height=6cm,
                title={Intersection: Nash Equilibrium},
                xlabel={$q$ (P2's prob of Head)},
                ylabel={$p$ (P1's prob of Head)},
                xmin=0, xmax=1,
                ymin=0, ymax=1,
                xtick={0, 0.5, 1},
                ytick={0, 0.5, 1},
                xticklabels={$0$, $\frac{1}{2}$, $1$},
                yticklabels={$0$, $\frac{1}{2}$, $1$},
                grid=major,
                legend pos=south east,
            ]
            \addplot[blue, very thick] coordinates {(0,0) (0.5,0)};
            \addplot[blue, very thick] coordinates {(0.5,1) (1,1)};
            \addplot[blue, very thick] coordinates {(0.5,0) (0.5,1)};
            \addlegendentry{$p = B_1(q)$}
            
            \addplot[red, very thick] coordinates {(1,0) (1,0.5)};
            \addplot[red, very thick] coordinates {(0,0.5) (0,1)};
            \addplot[red, very thick] coordinates {(0,0.5) (1,0.5)};
            \addlegendentry{$q = B_2(p)$}
            
            \node[circle, fill=black, inner sep=2pt, label={above right:{NE at $(\frac{1}{2}, \frac{1}{2})$}}] at (axis cs:0.5,0.5) {};
            \end{axis}
        \end{tikzpicture}
        \caption{Intersection of best response functions.}
        \label{fig:ne_intersection_final}
    \end{subfigure}
    
    \caption{Graphical representation of Best Response functions and the resulting Nash Equilibrium.}
    \label{fig:full_ne_graphs_final}
\end{figure}

\subsection{Existence of NE}

\subsection*{Nash's Existence}
Recall $\blacktriangleright$ \textbf{Minimax Theorem:} There exists a mixed strategy saddle-point solution for the finite zero-sum game. \\

Consider the zero-sum finite game $A$ then from \textit{minimax theorem}, there exists $(x^*, y^*) \in \Sigma_1 \times \Sigma_2$ such that, for any two-player, zero-sum game represented by player's $1$'s payoff matrix $A$:
\[
    \max_{x} \min_{y} x^T A y = \min_{y} \max_{x} (x^T) A y = x^{*T} A y^*
\]
where  $x^TAy$ is expected payoff for Player $1$ when the players use strategies $x$ $and$ $y$ and $x^{*T}Ay^* = v^*$ is value of the game.\\

Indeed, $(x^*, y^*) \in \Sigma_1 \times \Sigma_2$ is the saddle-point equilibrium

\textbf{Recall} saddle-point equilibrium for zero-sum $=$ NE for zero-sum\\

$\blacktriangleright$ A characterization of saddle-point equilibrium, the finite zero-sum game can be formulated via \textbf{\textit{linear program}}.

\begin{enumerate}
    \item Formulate player 1's $maximin$ as linear program
    \item Find $x$ to solve $max_x(min_yx^TAy)$
    \item Player $2$ will respond by $minimize$ $x^T Ay$. Therefore, only consider Player $2$'s \textit{pure strategies}. Player $2$ picks $column$ $j$ that yields $lowest$ $value$. Thus, $min_yx^TAy = min_j\sum^n_{i=1}a_{ij}x_{ij}$
    \item Let $z$ represent \textbf{guaranteed minimum payoff}. Player 1 chooses mixed strategy $x$ that makes guaranteed payoff as high as possible. Thus $z$ must be constraint to $z \leq min\{set\}$
    \item Apply same logic to player $2$ (Dual LP).
\end{enumerate}

The \textbf{Strong Duality Theorem} of linear programming states: if primal LP has optimal solution, then its dual has optimal solution and thus both objective values are equal.
\begin{center}
    $max$ $z = min$ $w = Minimax$   
\end{center}

\pf{
Note $\sum y_i = \sum x_i = 1$ Hence,
\begin{align*}
    \min_{y} x^T A y &= \min_{j} \sum_{i=1}^{n} a_{ij} x_i, \quad z \le \sum_{i=1}^{n} a_{ij} x_i, \forall j \\
    \max_{x} x^T A y &= \max_{i} \sum_{j=1}^{n} a_{ij} y_j, \quad \sum_{j=1}^{n} a_{ij} y_j \le w \quad \forall i
\end{align*}


\textbf{Primal Linear Program (Player 1)}

Hence,
\[
    \max_{x} \min_{y} x^T A y = \max_{x} \min_{j} \sum_{i=1}^{n} a_{ij} x_i
\]
Equivalent to
\begin{align*}
    \max \quad & z \\
    \text{subject to} \quad & \\
    & z - \sum_{i=1}^{n} a_{ij} x_i \le 0, \quad j=1, 2, \ldots, n \\
    & \sum_{i=1}^{n} x_i = 1, \quad x_i \ge 0, \quad i=1, 2, \ldots, n
\end{align*}


\textbf{Dual Linear Program (Player 2)}
Primal linear program for $x^*$ is:
\begin{align*}
    \max \quad & z \\
    \text{subject to} \quad & \\
    & z - \sum_{i=1}^{n} a_{ij} x_i \le 0, \quad j=1, 2, \ldots, n \\
    & \sum_{i=1}^{n} x_i = 1, \quad x_i \ge 0, \quad i=1, 2, \ldots, n
\end{align*}
and for $y^*$ (Dual program) is:
\begin{align*}
    \min \quad & w \\
    \text{subject to} \quad & \\
    & w - \sum_{j=1}^{n} a_{ij} y_j \ge 0, \quad i=1, 2, \ldots, n \\
    & \sum_{j=1}^{n} y_j = 1, \quad y_j \ge 0, \quad j=1, 2, \ldots, n
\end{align*}
{$\blacktriangleright$ Above two LPs are dual to each other}\\

\textbf{Converting into Standard LP Form}: LP formulations into standard matrix 

\[
    \max_{x} a^T x, \quad \text{subject to} \quad Ax \le c, x \ge 0
\]
Let $z = z_1 - z_2$, where $z_1 = z$ and $z_2 = w$ Then
\[
    \max_{x \in \mathbb{R}^n, z_1, z_2 \in \mathbb{R}} \begin{pmatrix} 1 & -1 & 0_n \end{pmatrix} \begin{pmatrix} z_1 \\ z_2 \\ x \end{pmatrix}
\]
\[
    \text{subject to} \quad \begin{pmatrix} -1_n & 1_n \end{pmatrix} \begin{pmatrix} z_1 \\ z_2 \end{pmatrix} \ge Ax,
\]
\[
    1_n^T x \le 1, \quad -1_n^T x \le -1
\]
Then transform it to standard LP form.

Equivalently $0$-$\sum$ game $=$ linear program:
\[
    \max_{x \in \mathbb{R}^n, z_1, z_2 \in \mathbb{R}} \begin{pmatrix} 0_n & 1 & -1 \end{pmatrix} \begin{pmatrix} x \\ z_1 \\ z_2 \end{pmatrix}
\]
\[
    \text{subject to} \quad
    \begin{pmatrix} 1_n^T & 0 & 0 \\ -1_n^T & 0 & 0 \\ A & 1_n & -1_n \end{pmatrix}
    \begin{pmatrix} x \\ z_1 \\ z_2 \end{pmatrix}
    \le
    \begin{pmatrix} 1 \\ -1 \\ 0_n \end{pmatrix}
\]
}

$\blacktriangleright$ Finding the solution to the saddle-point equilibrium to a $2-$player, $0-$sum game is $=$ solving a pair of dual linear programs.\\


Consider the Mathematical Framework of a Game:
\begin{enumerate}
    \item Strategy Space:
    \begin{itemize}
        \item $N=\{1,2,...,n\}$
        \item $S_i = \{s_{i1},s_{i2},...,s_{ik}\}$ (pure strategy) for $i \in N$
        \item $u_i: S \rightarrow \Re, S = S_1 * S_2 * ... * S_n$ for $i \in N$\\
        
        For $i$, $\sigma_i$ \textbf{mixed strategy} is probability distribution over pure strategies. $\sigma_i = (p_{i1}, p_{i2},...,p{ik})$. $p_{ij}$ is probability of playing pure strategy $s_{ij}$.\\
        
        \begin{enumerate}
            \item $p_{ij} \geq 0 \forall j \in \{1,...,k_i\}$
            \item $\sum^{k_i}_{j=1} P_{ij} = 1$
        \end{enumerate}
        Set of all possible mixed strategies for $i$ forms a \textbf{standard simplex} $\Delta_i$. \textit{Simplex}: Generalization of triangle to higher dimensions. e.g., $3 * S_i$ is triangle in $3D$ space.

        Set of all possible mixed strategy \textit{profiles} is the \textbf{Cartesian Product of the individual player's strategy simplices:}
        \begin{center}
            \[
            \Sigma = \Delta_1 * \Delta_2*...*\Delta_n
            \]
        \end{center}
        A point $\sigma = (\sigma_1,\sigma_2,...,\sigma_n) \in \Sigma$ is full profile of mixed strategies, $1$ for each $i \in N$
    \end{itemize}
    
    \item Properties of Strategy Space $\Sigma$

    Consider \textbf{Kakutani's Fixed-Point Theorem}:

    Let $S \subset \Re^n$. Let $f: S \rightarrow S$ be the set-valued mapping (correspondence function) with for $x \in S \rightarrow f(x) \subseteq S$. Assume the following holds:
    \begin{itemize}
        \item$\blacktriangleright$ $S$ is convex and compact
        \item$\blacktriangleright$ $f$ is non-empty for $x \in S$
        \item$\blacktriangleright$ For any $x \in S, f$ is convex  set, i.e., $f$ is a convex-valued mapping (correspondence).
        \item$\blacktriangleright$ $f$ is a closed graph, i.e., if $(x_k,y_k) \rightarrow (x,y)$ as $k \rightarrow \infty$ with $y_k \in f(x_k)$ then $y \in f(x)$

        Then $f$ has a fixed point, i.e., there is $x \in S$ such that $x \in f(x)$
        
    \end{itemize}
\textbf{\textit{Examples Graphical Illustration Kakutani's:}}\\

Conditions of theorem are violated and therefore no fixed point exists. Red line is \textit{identity line}. A fixed point exists wherever the graph of the mapping $f(x)$ intersects identity line
\begin{center}
    \includegraphics[scale=0.5]{katukani.png}    
\end{center}

\textbf{Right:} Mapping has a jump. As one approaches jump from left, output values on the curve approach the position of the open circle. AT that very input value the function's output is the filled circle. Therefore, the limit of the outputs(hollow) \textbf{is not} an element of the actual output set.\\

\textbf{Goal:} To find a fixed point. A \textbf{fixed point} of a mapping is an input that is also part of its own output. Thus a fixed point exists if $x \in f(x)$, this corresponds to NE. A set-valued mapping (correspondence) maps $x$ to a whole \textit{set of points}, $f(x)$. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%##########################
    
    \item Best-Response (set-valued mapping) Correspondence

\begin{equation}
u_i(\sigma) = \sum_{s \in S} \left( \prod_{j=1}^n \sigma_j(s_j) \right) u_i(s)
\end{equation}

where $\sigma_j(s_j)$ is probability player $j$ plays pure strategy $s_j$. Function is linear in each player's own probabilities and therefore continuous over entire space $\Sigma$.

Define\textbf{best-response correspondence} for player $i$, $B_i$. It takes the strategies of all other players, $\sigma_{-i} \in \Sigma_{-i}$, as input and returns set of all of player $i$'s mixed strategies that yield the maximum possible payoff.

\begin{equation}
B_i(\sigma_{-i}) = \left\{ \sigma_i^* \in \Delta_i \mid u_i(\sigma_i^*, \sigma_{-i}) \ge u_i(\sigma_i, \sigma_{-i}) \text{ for all } \sigma_i \in \Delta_i \right\}
\end{equation}

Term \textbf{correspondence} or \textbf{set-valued function} instead of "function" because there might be multiple best responses e.g., when player is indifferent between several strategies.

\end{enumerate}

\section{Correlated Equilibria}
\subsection{Correlated Equilibrium}
$\blacktriangleright$ Introduction of \textbf{Correlating Device}: It sends private signals to each player and signals from different players can be correlated. e.g., Traffic light is correlating device: if it signals \textcolor{green}{Green} to north-south traffic, it simultaneously signals \textcolor{red}{Red} to east-west traffic. 

$\blacktriangleright$ \textit{Solution concept} that generalizes NE. Description of stable outcome in a game where players coordinate their actions based on shared, external, and random correlating signal.

Signal recommends a pure strategy to each player and equilibrium holds if no player has incentive to unilaterally deviate from recommended strategy.\\

\textbf{Incentive Compatibility (Mechanism):} if $\forall i \in N$ can achieve own best outcome by reporting their $true$ preferences. 

\defn{Correlated Equilibrium}{
Consider a finite n-player game $\langle \mathcal{N}, (S_i)_{i \in \mathcal{I}}, (u_i)_{i \in \mathcal{I}} \rangle$ 

\begin{itemize}
    \item[$\blacktriangleright$] $N=\{1,...,n\}$
    \item[$\blacktriangleright$] Set $S_i$ of pure strategies for player $i$. $s = (s_1,...,s_n)$
    \item[$\blacktriangleright$] Set $S=S_1*...*S_n$ of pure strategy profiles
    \item[$\blacktriangleright$] $u_i : S \rightarrow \mathbb{R}$
\end{itemize}

A \textbf{Correlated Equilibrium} is probability distribution $p$ over set of all pure strategy profiles $S$.

\begin{center}
    $p:S \rightarrow [0,1]$ such that $\sum_{s\in S}P(s) = 1$
\end{center}

where $p(s)$ is probability recommended by correlating device. $p$ must satisfy \textit{incentive compatibility} constraint  $\forall i \in N$ and $\forall s_i \in S_i$.

\begin{equation}
\sum_{s_{-i} \in S_{-i}} p(s_i, s_{-i}) u_i(s_i, s_{-i}) \geq \sum_{s_{-i} \in S_{-i}} p(s_i', s_{-i}) u_i(s_i', s_{-i}) \quad \forall i \in N, \forall s_i, s_i' \in S_i
\end{equation}




}


\end{document}

